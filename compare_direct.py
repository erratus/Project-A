import os
import json
import time
from langchain_community.chat_models import ChatOllama
from langchain_core.messages import SystemMessage, HumanMessage

# === Paths and Config ===
resume_json_dir = "resume_json"
jd_json_dir = "JD_extraction"
model_name = "bigllama/mistralv01-7b:latest"

system_prompt = """You are a world-class HR, Talent Acquisition, and Generative AI Specialist with deep expertise in job-role alignment, semantic document comparison, and hiring decision automation.
You are tasked with comparing a candidate resume and a job description. Both are pre-parsed into structured fields: Skills, Education, Job Role, Experience, and Other Information. Your job is to assess the alignment **strictly based on meaning** — not exact keyword matches.
You must return a single valid JSON object in the structure described below.

### Instructions:

- Evaluate **semantic relevance**, not just keyword overlap. For example, treat "ML Engineer" and "Machine Learning Engineer" as identical.
- Use **real-world hiring logic**: If a resume **exceeds** the JD requirements (e.g., more skills, more education, deeper experience), the match_pct should be high — even **100%**.
- Avoid over-penalizing minor differences. Focus on **capability and fit**.
- NEVER hallucinate or infer information not explicitly present in either document.
- NEVER nest objects inside any field — your output must remain a **flat JSON**.
- Explanations must be **insightful, human-readable, and professional** — written as if speaking to a hiring manager.
- Do NOT use escape characters like \\_ for underscores - use plain underscores instead.
- Do NOT escape quotes unnecessarily - only escape when required by JSON syntax.
- Do **not** include any commentary or text outside the JSON.

### Field Matching Logic:

1. **Skills**
   - Match based on technical equivalence.
   - If the resume includes **all** required skills or **more**, assign **100%**.
   - If semantically similar (e.g., "pandas" vs. "data manipulation in Python"), still assign high match_pct (80–95%).

2. **Education**
   - If the candidate's education level is **equal or higher** than the JD, score high.
   - Degrees in relevant fields or from reputable institutions should be favored.

3. **Experience**
   - Match on role relevance, technologies used, domain familiarity, and years of experience.
   - Experience that directly meets or exceeds JD expectations should score high (90–100%).

4. **Job Role**
   - Normalize semantically equivalent titles (e.g., "ML Engineer" = "Machine Learning Engineer").
   - If the resume job role **exactly matches** or semantically aligns with **any title** in the job description, assign **100%**.
   - If the resume title is a **parent or superset role** of the JD (e.g., "Data Scientist" when JD asks for "ML Engineer"), assign a **high match percentage (90–95%)**.
   - If the resume title is a **subset** (e.g., "ML Engineer" when JD includes "Generative AI Engineer"), still assign **high score (90–95%)**, if contextually relevant.
   - Recognize hierarchical and domain relationships.
   - Penalize only when there is a **significant deviation** in domain, seniority, or function.

5. **OverallMatchPercentage**
   - Must be a weighted score calculated **heavily** from Skills, Experience, Education, and Job Role.
   - **Other Information** may provide a minor bonus/penalty (±5%).

6. **AI_Generated_Estimate_Percentage**
   - Estimate how likely the resume was generated by AI, based on repetition, unnatural tone, excessive perfection, or generic phrasing.

### Output Format (strict):

{
  "{resume_filename}": {
    "Skills": {
      "match_pct": float,
      "resume_value": string,
      "job_description_value": string,
      "explanation": string
    },
    "Education": {
      "match_pct": float,
      "resume_value": string,
      "job_description_value": string,
      "explanation": string
    },
    "Job Role": {
      "match_pct": float,
      "resume_value": string,
      "job_description_value": string,
      "explanation": string
    },
    "Experience": {
      "match_pct": float,
      "resume_value": string,
      "job_description_value": string,
      "explanation": string
    },
    "OverallMatchPercentage": float,
    "why_overall_match_is_this": string,
    "AI_Generated_Estimate_Percentage": float
  }
}

Return ONLY the JSON object. No extra comments or explanation."""

user_prompt_template = """Compare the following resume and job description using their parsed field data.

Each field below is populated from the JSON files. Compare them **semantically and intelligently** using the structure below.

Use the following strict JSON format:

{{
  "{resume_filename}": {{
    "Skills": {{
      "match_pct": float,
      "resume_value": string,
      "job_description_value": string,
      "explanation": string
    }},
    "Education": {{
      "match_pct": float,
      "resume_value": string,
      "job_description_value": string,
      "explanation": string
    }},
    "Job Role": {{
      "match_pct": float,
      "resume_value": string,
      "job_description_value": string,
      "explanation": string
    }},
    "Experience": {{
      "match_pct": float,
      "resume_value": string,
      "job_description_value": string,
      "explanation": string
    }},
    "OverallMatchPercentage": float,
    "why_overall_match_is_this": string,
    "AI_Generated_Estimate_Percentage": float
  }}
}}

Return only the JSON object, and ensure:
- match_pct values reflect real semantic similarity (not keyword count).
- Explanations are professional, specific, and insightful.
- No nested JSON objects inside any value fields.
- No semicolons (;) in values — use periods or commas.
- No hallucinated info or missing keys."""

def load_json_files(directory, file_type):
    """Load all JSON files from a directory"""
    files = []
    if not os.path.exists(directory):
        print(f"[ERROR] Directory {directory} does not exist!")
        return files
    
    for filename in os.listdir(directory):
        if filename.endswith('.json'):
            filepath = os.path.join(directory, filename)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    data['filename'] = filename
                    files.append(data)
                    print(f"[INFO] Loaded {file_type}: {filename}")
            except Exception as e:
                print(f"[ERROR] Failed to load {filename}: {e}")
    
    return files

def format_field_data(data, field_name):
    """Format field data for display"""
    field_data = data.get(field_name, [])
    if isinstance(field_data, list):
        return ', '.join(field_data) if field_data else "Not specified"
    return str(field_data) if field_data else "Not specified"

# === Load JSON Files ===
print("[INFO] Loading JSON files...")
resume_files = load_json_files(resume_json_dir, "resume")
jd_files = load_json_files(jd_json_dir, "job description")

# Validate that we have data
if not jd_files:
    print("[ERROR] No job descriptions found!")
    exit(1)

if not resume_files:
    print("[ERROR] No resumes found!")
    exit(1)

jd = jd_files[0]  # assume only 1 JD
print(f"[INFO] Using JD: {jd.get('filename', 'unknown')}")
print(f"[INFO] Found {len(resume_files)} resumes to compare")

chat = ChatOllama(model=model_name, temperature=0.0, seed=42)

def run_comparison(resume, jd, resume_filename):
    """Run comparison between resume and job description"""
    
    # Format the data for comparison
    resume_skills = format_field_data(resume, 'skill')
    resume_education = format_field_data(resume, 'education')
    resume_experience = format_field_data(resume, 'experience')
    resume_job_role = format_field_data(resume, 'job role')
    resume_other = format_field_data(resume, 'other information')
    
    jd_skills = format_field_data(jd, 'skill')
    jd_education = format_field_data(jd, 'education')
    jd_experience = format_field_data(jd, 'experience')
    jd_job_role = format_field_data(jd, 'job role')
    jd_other = format_field_data(jd, 'other information')
    
    user_prompt = user_prompt_template.format(
        resume_filename=resume_filename
    ) + f"""

Resume Data:
- Skills: {resume_skills}
- Education: {resume_education}
- Experience: {resume_experience}
- Job Role: {resume_job_role}
- Other Information: {resume_other}

Job Description Data:
- Skills: {jd_skills}
- Education: {jd_education}
- Experience: {jd_experience}
- Job Role: {jd_job_role}
- Other Information: {jd_other}"""

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt)
    ]

    try:
        print(f"[INFO] Processing resume: {resume_filename}")
        response = chat.invoke(messages)
        content = response.content.strip()
        
        # Clean up the response
        if content.startswith('```json'):
            content = content.replace('```json', '').replace('```', '').strip()
        elif content.startswith('```'):
            content = content.replace('```', '').strip()
        
        # Find JSON object
        json_start = content.find('{')
        json_end = content.rfind('}') + 1
        
        if json_start != -1 and json_end > json_start:
            json_content = content[json_start:json_end]
            
            # Fix common JSON escape issues
            json_content = json_content.replace('\\_', '_')
            json_content = json_content.replace('\\n', '\\\\n')
            json_content = json_content.replace('\\t', '\\\\t')
            
            result = json.loads(json_content)
            print(f"[SUCCESS] Successfully processed {resume_filename}")
            return result
        else:
            print(f"[ERROR] No valid JSON found in response for {resume_filename}")
            return {resume_filename: {"error": "No valid JSON found in LLM response", "raw_response": content}}
            
    except json.JSONDecodeError as e:
        print(f"[ERROR] JSON parsing failed for {resume_filename}: {e}")
        return {resume_filename: {"error": f"JSON parsing failed: {str(e)}", "raw_response": content}}
    except Exception as e:
        print(f"[ERROR] General error for {resume_filename}: {e}")
        return {resume_filename: {"error": str(e)}}

# === Run Comparisons ===
print(f"\n[INFO] Starting comparison process...")
print(f"[INFO] Job Description: {jd.get('filename', 'unknown')}")
print(f"[INFO] Number of resumes to process: {len(resume_files)}")
print("-" * 50)

results = {}
successful_matches = 0
failed_matches = 0

for i, resume in enumerate(resume_files, 1):
    fname = resume.get("filename", f"resume_{int(time.time())}.json")
    print(f"\n[{i}/{len(resume_files)}] Processing: {fname}")
    
    match = run_comparison(resume, jd, fname)
    results.update(match)
    
    # Check if the match was successful
    if fname in match and "error" not in match[fname]:
        successful_matches += 1
        print(f"[SUCCESS] Completed: {fname}")
    else:
        failed_matches += 1
        print(f"[FAILED] Error processing: {fname}")

print("\n" + "=" * 50)
print(f"[SUMMARY] Processing complete!")
print(f"[SUMMARY] Successful matches: {successful_matches}")
print(f"[SUMMARY] Failed matches: {failed_matches}")
print(f"[SUMMARY] Total processed: {len(resume_files)}")

# === Save Results ===
os.makedirs("output", exist_ok=True)
output_file = "output/resume_jd_matches_direct.json"

with open(output_file, "w", encoding="utf-8") as f:
    json.dump(results, f, indent=2, ensure_ascii=False)

print(f"\n[INFO] Results saved to: {output_file}")

# Print summary
print(f"\n[INFO] Match Summary:")
for resume_name, data in results.items():
    if "error" not in data and "OverallMatchPercentage" in data:
        overall_match = data.get("OverallMatchPercentage", 0)
        print(f"  {resume_name}: {overall_match}% overall match")
    elif "error" in data:
        print(f"  {resume_name}: ERROR - {data['error']}")

print(f"\nDirect JSON comparison completed successfully!")
